@article{docomba,
  title={COMBA-PROMPT: Comprehensive Benchmark and Augmentation for Verilog Generation Leveraging Dual-LLM Prompting},
  author={Nguyen, Vu-Minh-Thanh and Nguyen, Ngoc-Thien-Kim and Le, Duc-Hung},
  journal={Authorea Preprints},
  publisher={Authorea}
}

@INPROCEEDINGS{10691738,
  author={Zhang, Yongan and Yu, Zhongzhi and Fu, Yonggan and Wan, Cheng and Lin, Yingyan Celine},
  booktitle={2024 IEEE LLM Aided Design Workshop (LAD)}, 
  title={MG-Verilog: Multi-grained Dataset Towards Enhanced LLM-assisted Verilog Generation}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  keywords={Codes;Large language models;Conferences;Natural languages;Hardware;Complexity theory;Hardware design languages},
  doi={10.1109/LAD62341.2024.10691738}}

@misc{dettmers2023qloraefficientfinetuningquantized,
      title={QLoRA: Efficient Finetuning of Quantized LLMs}, 
      author={Tim Dettmers and Artidoro Pagnoni and Ari Holtzman and Luke Zettlemoyer},
      year={2023},
      eprint={2305.14314},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.14314}, 
}

@INPROCEEDINGS{11133406,
  author={Nadimi, Bardia and Boutaib, Ghali Omar and Zheng, Hao},
  booktitle={2025 62nd ACM/IEEE Design Automation Conference (DAC)}, 
  title={PyraNet: A Multi-Layered Hierarchical Dataset for Verilog}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  keywords={Codes;Design automation;Accuracy;Large language models;Transformers;Hardware design languages;Large Language Models;fine-tuning;Verilog;dataset;transformers},
  doi={10.1109/DAC63849.2025.1113340}}
@article{taori2023alpaca,
  title={Alpaca: A strong, replicable instruction-following model},
  author={Taori, Rohan and Gulrajani, Ishaan and Zhang, Tianyi and Dubois, Yann and Li, Xuechen and Guestrin, Carlos and Liang, Percy and Hashimoto, Tatsunori B},
  journal={Stanford Center for Research on Foundation Models. https://crfm. stanford. edu/2023/03/13/alpaca. html},
  volume={3},
  number={6},
  pages={7},
  year={2023}
}

@article{chiang2023vicuna,
  title={Vicuna: An open-source chatbot impressing gpt-4 with 90\%* chatgpt quality},
  author={Chiang, Wei-Lin and Li, Zhuohan and Lin, Ziqing and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E and others},
  journal={See https://vicuna. lmsys. org (accessed 14 April 2023)},
  volume={2},
  number={3},
  pages={6},
  year={2023}
}

@article{guo2024deepseek,
  title={DeepSeek-Coder: When the Large Language Model Meets Programming--The Rise of Code Intelligence},
  author={Guo, Daya and Zhu, Qihao and Yang, Dejian and Xie, Zhenda and Dong, Kai and Zhang, Wentao and Chen, Guanting and Bi, Xiao and Wu, Yu and Li, YK and others},
  journal={arXiv preprint arXiv:2401.14196},
  year={2024}
}

@article{liu2025rtlcoder,
  title={RTLCoder: Fully Open-Source and Efficient LLM-Assisted RTL Code Generation Technique},
  author={Liu, Shang and Fang, Wenji and Lu, Yao and Wang, Jing and Zhang, Qijun and Zhang, Hongce and Xie, Zhiyao},
  journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
  volume={44},
  number={4},
  pages={1448--1461},
  year={2025},
  publisher={IEEE}
}

@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallou{\'e}dec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}

@misc{chen2025rolesmallmodelsllm,
      title={What is the Role of Small Models in the LLM Era: A Survey}, 
      author={Lihu Chen and Gaël Varoquaux},
      year={2025},
      eprint={2409.06857},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2409.06857}, 
}

@inproceedings{
hu2022lora,
title={Lo{RA}: Low-Rank Adaptation of Large Language Models},
author={Edward J Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=nZeVKeeFYf9}
}

@article{YAO2024100211,
title = {A survey on large language model (LLM) security and privacy: The Good, The Bad, and The Ugly},
journal = {High-Confidence Computing},
volume = {4},
number = {2},
pages = {100211},
year = {2024},
issn = {2667-2952},
doi = {https://doi.org/10.1016/j.hcc.2024.100211},
url = {https://www.sciencedirect.com/science/article/pii/S266729522400014X},
author = {Yifan Yao and Jinhao Duan and Kaidi Xu and Yuanfang Cai and Zhibo Sun and Yue Zhang},
keywords = {Large Language Model (LLM), LLM security, LLM privacy, ChatGPT, LLM attacks, LLM vulnerabilities},
abstract = {Large Language Models (LLMs), such as ChatGPT and Bard, have revolutionized natural language understanding and generation. They possess deep language comprehension, human-like text generation capabilities, contextual awareness, and robust problem-solving skills, making them invaluable in various domains (e.g., search engines, customer support, translation). In the meantime, LLMs have also gained traction in the security community, revealing security vulnerabilities and showcasing their potential in security-related tasks. This paper explores the intersection of LLMs with security and privacy. Specifically, we investigate how LLMs positively impact security and privacy, potential risks and threats associated with their use, and inherent vulnerabilities within LLMs. Through a comprehensive literature review, the paper categorizes the papers into “The Good” (beneficial LLM applications), “The Bad” (offensive applications), and “The Ugly” (vulnerabilities of LLMs and their defenses). We have some interesting findings. For example, LLMs have proven to enhance code security (code vulnerability detection) and data privacy (data confidentiality protection), outperforming traditional methods. However, they can also be harnessed for various attacks (particularly user-level attacks) due to their human-like reasoning abilities. We have identified areas that require further research efforts. For example, Research on model and parameter extraction attacks is limited and often theoretical, hindered by LLM parameter scale and confidentiality. Safe instruction tuning, a recent development, requires more exploration. We hope that our work can shed light on the LLMs’ potential to both bolster and jeopardize cybersecurity.}
}

@Article{fi15060192,
AUTHOR = {Roumeliotis, Konstantinos I. and Tselikas, Nikolaos D.},
TITLE = {ChatGPT and Open-AI Models: A Preliminary Review},
JOURNAL = {Future Internet},
VOLUME = {15},
YEAR = {2023},
NUMBER = {6},
ARTICLE-NUMBER = {192},
URL = {https://www.mdpi.com/1999-5903/15/6/192},
ISSN = {1999-5903},
ABSTRACT = {According to numerous reports, ChatGPT represents a significant breakthrough in the field of artificial intelligence. ChatGPT is a pre-trained AI model designed to engage in natural language conversations, utilizing sophisticated techniques from Natural Language Processing (NLP), Supervised Learning, and Reinforcement Learning to comprehend and generate text comparable to human-generated text. This article provides an overview of the training process and fundamental functionality of ChatGPT, accompanied by a preliminary review of the relevant literature. Notably, this article presents the first comprehensive literature review of this technology at the time of publication, aiming to aggregate all the available pertinent articles to facilitate further developments in the field. Ultimately, the authors aim to offer an appraisal of the technology’s potential implications on existing knowledge and technology, along with potential challenges that must be addressed.},
DOI = {10.3390/fi15060192}
}

@INPROCEEDINGS{10323812,
  author={Liu, Mingjie and Pinckney, Nathaniel and Khailany, Brucek and Ren, Haoxing},
  booktitle={2023 IEEE/ACM International Conference on Computer Aided Design (ICCAD)}, 
  title={Invited Paper: VerilogEval: Evaluating Large Language Models for Verilog Code Generation}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  keywords={Codes;Design automation;Benchmark testing;Hardware;Distance measurement;Combinational circuits;Hardware design languages},
  doi={10.1109/ICCAD57390.2023.10323812}}

@article{10.1145/3718088,
author = {Pinckney, Nathaniel and Batten, Christopher and Liu, Mingjie and Ren, Haoxing and Khailany, Brucek},
title = {Revisiting VerilogEval: A Year of Improvements in Large-Language Models for Hardware Code Generation},
year = {2025},
issue_date = {November 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {6},
issn = {1084-4309},
url = {https://doi.org/10.1145/3718088},
doi = {10.1145/3718088},
abstract = {The application of large language models (LLMs) to digital hardware code generation is an emerging field, with most LLMs primarily trained on natural language and software code. Hardware code like Verilog constitutes a small portion of training data, and few hardware benchmarks exist. The open-source VerilogEval benchmark, released in November 2023, provided a consistent evaluation framework for LLMs on code completion tasks. Since then, both commercial and open models have seen significant development.In this work, we evaluate new commercial and open models since VerilogEval’s original release—including GPT-4o, GPT-4 Turbo, Llama3.1 (8B/70B/405B), Llama3 70B, Mistral Large, DeepSeek Coder (33B and 6.7B), CodeGemma 7B, and RTL-Coder—against an improved VerilogEval benchmark suite. We find measurable improvements in state-of-the-art models: GPT-4o achieves a 63\% pass rate on specification-to-RTL tasks. The recently released and open Llama3.1 405B achieves a 58\% pass rate, almost matching GPT-4o, while the smaller domain-specific RTL-Coder 6.7B models achieve an impressive 34\% pass rate.Additionally, we enhance VerilogEval’s infrastructure by automatically classifying failures, introducing in-context learning support, and extending the tasks to specification-to-RTL translation. We find that prompt engineering remains crucial for achieving good pass rates and varies widely with model and task. A benchmark infrastructure that allows for prompt engineering and failure analysis is essential for continued model development and deployment.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = oct,
articleno = {91},
numpages = {20},
keywords = {Large language models, RTL code generation, benchmarks}
}

@online{gpt4o,
	title={Hello GPT-4o},
    author={OpenAI},
	url={https://openai.com/index/hello-gpt-4o/},
	urldate = {2024-12-19},
    year = {2024},
    date = {2024-05-13}
}

@online{gpt4_turbo_announce,
    author = {OpenAI},
	title = {New models and developer products announced at {DevDay}},
	url = {https://openai.com/index/new-models-and-developer-products-announced-at-devday/},
	abstract = {{GPT}-4 Turbo with 128K context and lower prices, the new Assistants {API}, {GPT}-4 Turbo with Vision, {DALL}·E 3 {API}, and more.},
    date = {2023-11-06},
    year = {2023},
	urldate = {2024-05-28},
	langid = {american},
	file = {Snapshot:/Users/npfet/Zotero/storage/XVZXPLB9/new-models-and-developer-products-announced-at-devday.html:text/html},
}

@misc{gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2023},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@online{ai_au_2024,
	title = {Au Large},
	url = {https://mistral.ai/news/mistral-large/},
	abstract = {Mistral Large is our flagship model, with top-tier reasoning capacities. It is also available on Azure.},
	author = {Mistral AI},
	urldate = {2024-05-31},
	date = {2024-02-26},
	langid = {english},
	note = {Section: news},
	file = {Snapshot:/Users/npfet/Zotero/storage/QQWNCVZ9/mistral-large.html:text/html},
    year = {2024},

}

@online{noauthor_meta-llamallama3_2024,
    author = {Meta},
 	title = {meta-llama/llama-models},
	url = {https://github.com/meta-llama/llama-models},
	abstract = {Utilities intended for use with Llama models.},
	publisher = {Meta Llama},
	urldate = {2024-08-16},
	date = {2024-08-16},
	note = {original-date: 2024-06-27T22:14:09Z},
    year = {2024}
}

@online{noauthor_meta-llamacodellama-70b-instruct-hf_2024,
    author = {Meta},
	title = {meta-llama/{CodeLlama}-70b-Instruct-hf · Hugging Face},
	url = {https://huggingface.co/meta-llama/CodeLlama-70b-Instruct-hf},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2024-05-28},
	date = {2024-04-18},
}

@misc{guo2024deepseekcoder,
      title={DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence}, 
      author={Daya Guo and Qihao Zhu and Dejian Yang and Zhenda Xie and Kai Dong and Wentao Zhang and Guanting Chen and Xiao Bi and Y. Wu and Y. K. Li and Fuli Luo and Yingfei Xiong and Wenfeng Liang},
      year={2024},
      eprint={2401.14196},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@online{noauthor_googlecodegemma-7b_2024,
    author = {Google},
	title = {google/codegemma-7b · Hugging Face},
	url = {https://huggingface.co/google/codegemma-7b},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2024-05-28},
	date = {2024-05-14},
	file = {Snapshot:/Users/npfet/Zotero/storage/UVC6G9CF/codegemma-7b.html:text/html},
}

@article{10.1145/3768165,
author = {Wang, Fali and Zhang, Zhiwei and Zhang, Xianren and Wu, Zongyu and Mo, TzuHao and Lu, Qiuhao and Wang, Wanjing and Li, Rui and Xu, Junjie and Tang, Xianfeng and He, Qi and Ma, Yao and Huang, Ming and Wang, Suhang},
title = {A Comprehensive Survey of Small Language Models in the Era of Large Language Models: Techniques, Enhancements, Applications, Collaboration with LLMs, and Trustworthiness},
year = {2025},
issue_date = {December 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {6},
issn = {2157-6904},
url = {https://doi.org/10.1145/3768165},
doi = {10.1145/3768165},
abstract = {Large language models (LLMs) have demonstrated emergent abilities in text generation, question answering, and reasoning, facilitating various tasks and domains. Despite their proficiency in various tasks, LLMs like PaLM 540B and Llama-3.1 405B face limitations due to large parameter sizes and computational demands, often requiring cloud API use, which raises privacy concerns, limits real-time applications on edge devices, and increases fine-tuning costs. Additionally, LLMs often underperform in specialized domains such as healthcare and law due to insufficient domain-specific knowledge, necessitating specialized models. Therefore, Small Language Models (SLMs) are increasingly favored for their low inference latency, cost-effectiveness, efficient development, and easy customization and adaptability. These models are particularly well-suited for resource-limited environments and domain knowledge acquisition, addressing LLMs’ challenges and proving ideal for applications that require localized data handling for privacy, minimal inference latency for efficiency, and domain knowledge acquisition through lightweight fine-tuning. The rising demand for SLMs has spurred extensive research and development. However, a comprehensive survey investigating issues related to the definition, acquisition, application, enhancement, and reliability of SLM remains lacking, prompting us to conduct a detailed survey on these topics. The definition of SLMs varies widely; thus, to standardize, we propose defining SLMs by their capability to perform specialized tasks and suitability for resource-constrained settings, setting boundaries based on the minimal size for emergent abilities and the maximum size sustainable under resource constraints. For other aspects, we provide a taxonomy of relevant models/methods and develop general frameworks for each category to enhance and utilize SLMs effectively. We have compiled the collected SLM models and related methods on GitHub: .},
journal = {ACM Trans. Intell. Syst. Technol.},
month = nov,
articleno = {145},
numpages = {87},
keywords = {Small Language Models, On-Device LLMs, Domain-specific Models, Trustworthiness}
}

@article{10.1145/3641289,
author = {Chang, Yupeng and Wang, Xu and Wang, Jindong and Wu, Yuan and Yang, Linyi and Zhu, Kaijie and Chen, Hao and Yi, Xiaoyuan and Wang, Cunxiang and Wang, Yidong and Ye, Wei and Zhang, Yue and Chang, Yi and Yu, Philip S. and Yang, Qiang and Xie, Xing},
title = {A Survey on Evaluation of Large Language Models},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {3},
issn = {2157-6904},
url = {https://doi.org/10.1145/3641289},
doi = {10.1145/3641289},
abstract = {Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications. As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks. Over the past years, significant efforts have been made to examine LLMs from various perspectives. This paper presents a comprehensive review of these evaluation methods for LLMs, focusing on three key dimensions: what to evaluate, where to evaluate, and how to evaluate. Firstly, we provide an overview from the perspective of evaluation tasks, encompassing general natural language processing tasks, reasoning, medical usage, ethics, education, natural and social sciences, agent applications, and other areas. Secondly, we answer the ‘where’ and ‘how’ questions by diving into the evaluation methods and benchmarks, which serve as crucial components in assessing the performance of LLMs. Then, we summarize the success and failure cases of LLMs in different tasks. Finally, we shed light on several future challenges that lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to researchers in the realm of LLMs evaluation, thereby aiding the development of more proficient LLMs. Our key point is that evaluation should be treated as an essential discipline to better assist the development of LLMs. We consistently maintain the related open-source materials at:},
journal = {ACM Trans. Intell. Syst. Technol.},
month = mar,
articleno = {39},
numpages = {45},
keywords = {Large language models, evaluation, model assessment, benchmark}
}

@article{10.1145/3639372,
author = {Zhao, Haiyan and Chen, Hanjie and Yang, Fan and Liu, Ninghao and Deng, Huiqi and Cai, Hengyi and Wang, Shuaiqiang and Yin, Dawei and Du, Mengnan},
title = {Explainability for Large Language Models: A Survey},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {2157-6904},
url = {https://doi.org/10.1145/3639372},
doi = {10.1145/3639372},
abstract = {Large language models (LLMs) have demonstrated impressive capabilities in natural language processing. However, their internal mechanisms are still unclear and this lack of transparency poses unwanted risks for downstream applications. Therefore, understanding and explaining these models is crucial for elucidating their behaviors, limitations, and social impacts. In this article, we introduce a taxonomy of explainability techniques and provide a structured overview of methods for explaining Transformer-based language models. We categorize techniques based on the training paradigms of LLMs: traditional fine-tuning-based paradigm and prompting-based paradigm. For each paradigm, we summarize the goals and dominant approaches for generating local explanations of individual predictions and global explanations of overall model knowledge. We also discuss metrics for evaluating generated explanations and discuss how explanations can be leveraged to debug models and improve performance. Lastly, we examine key challenges and emerging opportunities for explanation techniques in the era of LLMs in comparison to conventional deep learning models.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = feb,
articleno = {20},
numpages = {38},
keywords = {Explainability, interpretability, large language models}
}

@inproceedings{cui-etal-2025-recent,
    title = "Recent Advances in Speech Language Models: A Survey",
    author = "Cui, Wenqian  and
      Yu, Dianzhi  and
      Jiao, Xiaoqi  and
      Meng, Ziqiao  and
      Zhang, Guangyan  and
      Wang, Qichao  and
      Guo, Steven Y.  and
      King, Irwin",
    editor = "Che, Wanxiang  and
      Nabende, Joyce  and
      Shutova, Ekaterina  and
      Pilehvar, Mohammad Taher",
    booktitle = "Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2025",
    address = "Vienna, Austria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.acl-long.682/",
    doi = "10.18653/v1/2025.acl-long.682",
    pages = "13943--13970",
    ISBN = "979-8-89176-251-0",
    abstract = "Text-based Large Language Models (LLMs) have recently gained significant attention, primarily for their capabilities in text-based interactions. However, natural human interaction often relies on speech, highlighting the need for voice-based models. In this context, Speech Language Models (SpeechLMs){---}foundation models designed to understand and generate speech{---}emerge as a promising solution for end-to-end speech interaction. This survey offers a comprehensive overview of recent approaches to building SpeechLMs, outlining their core architectural components, training methodologies, evaluation strategies, and the challenges and potential directions for future research in this rapidly advancing field. The GitHub repository is available at https://github.com/dreamtheater123/Awesome-SpeechLM-Survey"
}

@article{yin2024survey,
  title={A survey on multimodal large language models},
  author={Yin, Shukang and Fu, Chaoyou and Zhao, Sirui and Li, Ke and Sun, Xing and Xu, Tong and Chen, Enhong},
  journal={National Science Review},
  volume={11},
  number={12},
  pages={nwae403},
  year={2024},
  publisher={Oxford University Press}
}

@article{10.1145/3695988,
author = {Hou, Xinyi and Zhao, Yanjie and Liu, Yue and Yang, Zhou and Wang, Kailong and Li, Li and Luo, Xiapu and Lo, David and Grundy, John and Wang, Haoyu},
title = {Large Language Models for Software Engineering: A Systematic Literature Review},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {8},
issn = {1049-331X},
url = {https://doi.org/10.1145/3695988},
doi = {10.1145/3695988},
abstract = {Large Language Models (LLMs) have significantly impacted numerous domains, including Software Engineering (SE). Many recent publications have explored LLMs applied to various SE tasks. Nevertheless, a comprehensive understanding of the application, effects, and possible limitations of LLMs on SE is still in its early stages. To bridge this gap, we conducted a Systematic Literature Review (SLR) on LLM4SE, with a particular focus on understanding how LLMs can be exploited to optimize processes and outcomes. We selected and analyzed 395 research articles from January 2017 to January 2024 to answer four key Research Questions (RQs). In RQ1, we categorize different LLMs that have been employed in SE tasks, characterizing their distinctive features and uses. In RQ2, we analyze the methods used in data collection, pre-processing, and application, highlighting the role of well-curated datasets for successful LLM for SE implementation. RQ3 investigates the strategies employed to optimize and evaluate the performance of LLMs in SE. Finally, RQ4 examines the specific SE tasks where LLMs have shown success to date, illustrating their practical contributions to the field. From the answers to these RQs, we discuss the current state-of-the-art and trends, identifying gaps in existing research, and highlighting promising areas for future study. Our artifacts are publicly available at .},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = dec,
articleno = {220},
numpages = {79},
keywords = {Software Engineering, Large Language Model, Survey}
}

@ARTICLE{10876858,
  author={Guo, Cong and Cheng, Feng and Du, Zhixu and Kiessling, James and Ku, Jonathan and Li, Shiyu and Li, Ziru and Ma, Mingyuan and Molom-Ochir, Tergel and Morris, Benjamin and Shan, Haoxuan and Sun, Jingwei and Wang, Yitu and Wei, Chiyue and Wu, Xueying and Wu, Yuhao and Yang, Hao Frank and Zhang, Jingyang and Zhang, Junyao and Zheng, Qilin and Zhou, Guanglei and Li, Hai and Chen, Yiran},
  journal={IEEE Circuits and Systems Magazine}, 
  title={A Survey: Collaborative Hardware and Software Design in the Era of Large Language Models}, 
  year={2025},
  volume={25},
  number={1},
  pages={35-57},
  keywords={Large language models;Artificial intelligence;Natural language processing;Multimodal sensors;Energy consumption;Deep learning;Training;Hardware design languages;Algorithm design and analysis;Software algorithms;Inference algorithms;Next generation networking;Collaborative software;Large language model;hardware-software co-design},
  doi={10.1109/MCAS.2024.3476008}}

@article{chang2023improving,
  title={Improving large language model hardware generating quality through post-llm search},
  author={Chang, Kaiyan and Ren, Haimeng and Wang, Mengdi and Liang, Shengwen and Han, Yinhe and Li, Huawei and Li, Xiaowei and Wang, Ying},
  journal={Proceedings of the Machine Learning for Systems},
  year={2023}
}

@inproceedings{lu2024rtllm,
  title={Rtllm: An open-source benchmark for design rtl generation with large language model},
  author={Lu, Yao and Liu, Shang and Zhang, Qijun and Xie, Zhiyao},
  booktitle={2024 29th Asia and South Pacific Design Automation Conference (ASP-DAC)},
  pages={722--727},
  year={2024},
  organization={IEEE}
}

@article{joel2024survey,
  title={A survey on llm-based code generation for low-resource and domain-specific programming languages},
  author={Joel, Sathvik and Wu, Jie and Fard, Fatemeh},
  journal={ACM Transactions on Software Engineering and Methodology},
  year={2024},
  publisher={ACM New York, NY}
}

@inproceedings{gubbi2025prompting,
  title={Prompting for Power: Benchmarking Large Language Models for Low-Power RTL Design Generation},
  author={Gubbi, Kevin Immanuel and Halm, Marcus and Kumar, Sarbani and Sudarshan, Arvind and Kota, Pavan Dheeraj and Tarighat, Mohammadnavid and Sasan, Avesta and Homayoun, Houman},
  booktitle={2025 ACM/IEEE 7th Symposium on Machine Learning for CAD (MLCAD)},
  pages={1--7},
  year={2025},
  organization={IEEE}
}

@inproceedings{bhattacharyya2024llm,
  title={LLM vs HLS for RTL Code Generation: Friend or Foe?},
  author={Bhattacharyya, Sutirtha and Sutharshanan, BG and Karfa, Chandan},
  booktitle={2024 IEEE 33rd Asian Test Symposium (ATS)},
  pages={1--6},
  year={2024},
  organization={IEEE}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@inproceedings{tang2025hivegen,
  title={Hivegen--hierarchical llm-based verilog generation for scalable chip design},
  author={Tang, Jinwei and Qin, Jiayin and Thorat, Kiran and Zhu-Tian, Chen and Cao, Yu and Zhao, Yang Katie and Ding, Caiwen},
  booktitle={2025 IEEE International Conference on LLM-Aided Design (ICLAD)},
  pages={30--36},
  year={2025},
  organization={IEEE}
}

@inproceedings{ho2025verilogcoder,
  title={Verilogcoder: Autonomous verilog coding agents with graph-based planning and abstract syntax tree (ast)-based waveform tracing tool},
  author={Ho, Chia-Tung and Ren, Haoxing and Khailany, Brucek},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={39},
  number={1},
  pages={300--307},
  year={2025}
}

@article{10.1145/3715324,
author = {Pan, Jingyu and Zhou, Guanglei and Chang, Chen-Chia and Jacobson, Isaac and Hu, Jiang and Chen, Yiran},
title = {A Survey of Research in Large Language Models for Electronic Design Automation},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {3},
issn = {1084-4309},
url = {https://doi.org/10.1145/3715324},
doi = {10.1145/3715324},
abstract = {Within the rapidly evolving domain of Electronic Design Automation (EDA), Large Language Models (LLMs) have emerged as transformative technologies, offering unprecedented capabilities for optimizing and automating various aspects of electronic design. This survey provides a comprehensive exploration of LLM applications in EDA, focusing on advancements in model architectures, the implications of varying model sizes, and innovative customization techniques that enable tailored analytical insights. By examining the intersection of LLM capabilities and EDA requirements, the article highlights the significant impact these models have on extracting nuanced understandings from complex datasets. Furthermore, it addresses the challenges and opportunities in integrating LLMs into EDA workflows, paving the way for future research and application in this dynamic field. Through this detailed analysis, the survey aims to offer valuable insights to professionals in the EDA industry, AI researchers, and anyone interested in the convergence of advanced AI technologies and electronic design.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = feb,
articleno = {34},
numpages = {21},
keywords = {Large language models, machine learning, electronic design automation}
}

@inproceedings{10.1145/3649476.3660390,
author = {Akyash, Mohammad and M Kamali, Hadi},
title = {Evolutionary Large Language Models for Hardware Security: A Comparative Survey},
year = {2024},
isbn = {9798400706059},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649476.3660390},
doi = {10.1145/3649476.3660390},
abstract = {Automating hardware (HW) security vulnerability detection and mitigation during the design phase is imperative for two reasons: (i) It must be before chip fabrication, as post-fabrication fixes can be costly or even impractical; (ii) The size and complexity of modern HW raise concerns about unknown vulnerabilities compromising CIA triad. While Large Language Models (LLMs) can revolutionize both HW design and testing processes, within the semiconductor context, LLMs can be harnessed to automatically rectify security-relevant vulnerabilities inherent in HW designs. This study explores the seeds of LLM integration in register transfer level (RTL) designs, focusing on their capacity for autonomously resolving security-related vulnerabilities. The analysis involves comparing methodologies, assessing scalability, interpretability, and identifying future research directions. Potential areas for exploration include developing specialized LLM architectures for HW security tasks and enhancing model performance with domain-specific knowledge, leading to reliable automated security measurement and risk mitigation associated with HW vulnerabilities.},
booktitle = {Proceedings of the Great Lakes Symposium on VLSI 2024},
pages = {496–501},
numpages = {6},
keywords = {Hardware Security, Large Language Models, RTL Debugging},
location = {Clearwater, FL, USA},
series = {GLSVLSI '24}
}

@inproceedings{10.1145/3676536.3697118,
author = {Liu, Shang and Lu, Yao and Fang, Wenji and Li, Mengming and Xie, Zhiyao},
title = {OpenLLM-RTL: Open Dataset and Benchmark for LLM-Aided Design RTL Generation},
year = {2025},
isbn = {9798400710773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676536.3697118},
doi = {10.1145/3676536.3697118},
abstract = {The automated generation of design RTL based on large language model (LLM) and natural language instructions has demonstrated great potential in agile circuit design. However, the lack of datasets and benchmarks in the public domain prevents the development and fair evaluation of LLM solutions. This paper highlights our latest advances in open datasets and benchmarks from three perspectives: (1) RTLLM 2.0, an updated benchmark assessing LLM's capability in design RTL generation. The benchmark is augmented to 50 hand-crafted designs. Each design provides the design description, test cases, and a correct RTL code. (2) AssertEval, an open-source benchmark assessing the LLM's assertion generation capabilities for RTL verification. The benchmark includes 18 designs, each providing specification, signal definition, and correct RTL code. (3) RTLCoder-Data, an extended open-source dataset with 80K instruction-code data samples. Moreover, we propose a new verification-based method to verify the functionality correctness of training data samples. Based on this technique, we further release a dataset with 7K verified high-quality samples. These three studies are integrated into one framework, providing off-the-shelf support for the development and evaluation of LLMs for RTL code generation and verification. Finally, extensive experiments indicate that LLM performance can be boosted by enlarging the training dataset, improving data quality, and improving the training scheme.},
booktitle = {Proceedings of the 43rd IEEE/ACM International Conference on Computer-Aided Design},
articleno = {60},
numpages = {9},
keywords = {LLM-assisted circuit design, electronic design automation},
location = {Newark Liberty International Airport Marriott, New York, NY, USA},
series = {ICCAD '24}
}

@article{ALSAQER20252392,
title = {The potential of LLMs in hardware design},
journal = {Journal of Engineering Research},
volume = {13},
number = {3},
pages = {2392-2404},
year = {2025},
issn = {2307-1877},
doi = {https://doi.org/10.1016/j.jer.2024.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S2307187724002177},
author = {Shadan Alsaqer and Sarah Alajmi and Imtiaz Ahmad and Mohammad Alfailakawi},
keywords = {Artificial intelligence, Large language models, Natural language processing, Electronic design automation, GPT, Hardware design, Security, Verilog},
abstract = {The unprecedented success of Large Language Models (LLMs) like ChatGPT across diverse domains such as natural language understanding and coding has paved the way for their use in designing hardware to enhance productivity and reduce cost. Despite LLMs popularity in hardware design from both academia and industry, this emerging field remains unexplored, signaling a pressing need for a thorough examination and validation of these innovative methods. In this timely survey, we first briefly discuss the emergence of LLMs to revolutionize the hardware design process and then offer an in-depth analysis of existing state-of-the-art techniques in this field, which are classified into two categories: generating Verilog code and enhancing hardware security. Next, for each category, we analyze and summarize key potentials and challenges of the available techniques to provide an insightful discussion that will enable researchers, engineers, and practitioners to easily choose the right approach for their specific needs. We also report the security and privacy related limitations of the existing LLMs which must be carefully considered for chip design. Finally, we delineate some inspiring research directions to fully realize the untapped potential of the emergent LLMs technology in shaping the future of hardware design and verification.}
}

@INPROCEEDINGS{11133191,
  author={Zhao, Yujie and Zhang, Hejia and Huang, Hanxian and Yu, Zhongming and Zhao, Jishen},
  booktitle={2025 62nd ACM/IEEE Design Automation Conference (DAC)}, 
  title={MAGE: A Multi-Agent Engine for Automated RTL Code Generation}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  keywords={Codes;Accuracy;Navigation;Natural languages;Debugging;Syntactics;Reliability engineering;Space exploration;Hardware design languages;Multi-agent systems},
  doi={10.1109/DAC63849.2025.11133191}}

@misc{nadimi2025verimindagenticllmautomated,
      title={VeriMind: Agentic LLM for Automated Verilog Generation with a Novel Evaluation Metric}, 
      author={Bardia Nadimi and Ghali Omar Boutaib and Hao Zheng},
      year={2025},
      eprint={2503.16514},
      archivePrefix={arXiv},
      primaryClass={cs.AR},
      url={https://arxiv.org/abs/2503.16514}, 
}

@inproceedings{wolf2013yosys,
  title={Yosys-a free Verilog synthesis suite},
  author={Wolf, Clifford and Glaser, Johann and Kepler, Johannes},
  booktitle={Proceedings of the 21st Austrian Workshop on Microelectronics (Austrochip)},
  volume={97},
  year={2013}
}

@inproceedings{10.1145/3691621.3694934,
author = {Siddiq, Mohammed Latif and da Silva Santos, Joanna Cecilia and Devareddy, Sajith and Muller, Anna},
title = {SALLM: Security Assessment of Generated Code},
year = {2024},
isbn = {9798400712494},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691621.3694934},
doi = {10.1145/3691621.3694934},
abstract = {With the growing popularity of Large Language Models (LLMs) in software engineers' daily practices, it is important to ensure that the code generated by these tools is not only functionally correct but also free of vulnerabilities. Although LLMs can help developers to be more productive, prior empirical studies have shown that LLMs can generate insecure code. There are two contributing factors to the insecure code generation. First, existing datasets used to evaluate LLMs do not adequately represent genuine software engineering tasks sensitive to security. Instead, they are often based on competitive programming challenges or classroom-type coding tasks. In real-world applications, the code produced is integrated into larger codebases, introducing potential security risks. Second, existing evaluation metrics primarily focus on the functional correctness of the generated code while ignoring security considerations. Therefore, in this paper, we described Sallm, a framework to benchmark LLMs' abilities to generate secure code systematically. This framework has three major components: a novel dataset of security-centric Python prompts, configurable assessment techniques to evaluate the generated code, and novel metrics to evaluate the models' performance from the perspective of secure code generation.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering Workshops},
pages = {54–65},
numpages = {12},
keywords = {security evaluation, large language models, pre-trained transformer model, metrics},
location = {Sacramento, CA, USA},
series = {ASEW '24}
}